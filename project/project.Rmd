---
title: "Wikipedia Popularity"
author: "Duke Squirrels"
date: "04/19/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Load Packages

```{r load-packages, message=FALSE}
library(tidyverse)
library(broom)
```

## Load Data

```{r load-data, message=FALSE}
panth <- read_csv("data/cdatabase.csv",
                  na = c("Unknown", "1237?", "530s"))
```

## Introduction
 
The data that we obtained contains information regarding historical figures. We downloaded the data from Kaggle, but the data was collected by the Massachusetts Institute of Technology about a year ago. The data is based off of metrics from many wikipedia pages and believe the variables in the dataframe can be used to extrapolate what makes a historical figure "popular" by Wikipedia standards.  
By the end of our data analysis, we aim to derive the perfect combination of variables that lead to a high popularity index, which is recorded in the dataframe.
 
It is important to note that the dataframe has been updated as recently as last year and the last historical figure's birth year recorded was 2005, suggesting that though the dataframe has not added a historical figure born after the year 2005, there is still currently data being collected on the ones already in the dataframe (ie page views, article languages, etc.).
 
### Section 1- Introduction to the Data

```{r filter_NAs_rank_data}
panth_mod <- na.omit(panth)

panth_mod %>%
  ncol()

panth_mod %>%
  nrow()

panth_mod <- panth_mod %>%
  mutate(
    rank = 1:nrow(panth_mod)
  )

panth_mod %>%
  select(rank, full_name, birth_year, historical_popularity_index) %>%
  head(10)
```
 
There are 17 variables and 10,279 observations (with all NAs removed in the new dataframe). Before removing the NAs, the full dataframe had 11,341 observations.
 
In addition, we decided to rank the historical figures to based off of their `historical_popularity_index`.

### Mapping

```{r popularity-across-globe, fig.width=13, fig.height=5}
ggplot(panth_mod, mapping = aes(x = longitude, y = latitude, color = historical_popularity_index)) +
  geom_point() +
  theme_minimal() +
  labs(title = "Historical Popularity Index Around the World", x = "Longitude", 
       y = "Latitude", color = "Popularity Index Gradient")
```
 
 From this visual, we can see that the areas of the world that are generally uninhabitable or extremely rural do not have historical figures. For example, the center of South America, a large portion of North Africa, most of Russia, and a big portion of Australia. Additionally, in these countries and continents, the coast seems to have the most historical figures. 
 
### Section 2 - How the Variable `Domain` Affects `Historical_Popularity_Index`

```{r looking_at_data}
panth_mod %>%
  count(domain) %>%
  arrange(desc(n))

panth_mod %>%
  count(continent) %>%
  arrange(desc(n))
```

Looking at simply the number of historical figures in each of the domain categories, it becomes easier to see which domain has the most number of historical figures. When looking at the number of historical figures by continent, Europe is the continent with the most historical figures across the ~5000 year timespan of the data with more historical figures than all other continents combined.

### Simple Linear Regression

```{r domain_linear_model}
domain_m <- lm(historical_popularity_index ~ domain, data = panth_mod)
tidy(domain_m) %>%
  select(term, estimate)
```

Here we estimated the historical popularity index using the `domain` variable using a simple linear regression. The slope for the level in `domain` named `Business & Law` is 0.502, suggesting that historical figures who belong in the `Business & Law` domain have, on average, an increase in their overall popularity index of 0.502 as long as all other variables are held constant.
 
The linear model, based on the output, is:
 
`(historical_popularity_index) = 21.839(intercept) + 0.502(domainBusiness & Law) + 1.710(domainExploration) + 2.448(domainHumanities) + 1.716(domainInstitutions) + 0.532(domainPublic Figure) + 1.534(Science & Technology) - 4.112(domainSports)`

```{r r-squared_domain}
glance(domain_m)$r.squared
```

We found that the r-squared for the linear model `domain_m` is 40.1%, which suggests that 40.1% of the variability of the data can be explained by the linear model and that the model does fit our data pretty well. In the next few steps, we will continue to re-evaluate our model to determine what combination of variables result in a high or low popularity index score.
 
### Section 3 - How the Variable `Sex` Affects `Historical_Popularity_Index`

```{r men-and-women}
panth_mod %>%
  count(sex) %>%
  mutate(prop = n/sum(n))
```

Based on the filtered dataframe, there are 1,427 women and 8,852 men that are considered historical figures of the total 10,279 historical figures. There are about 6.2 times as many historical men than women overall in the data. The timeframe of this data starts at `r panth_mod%>%arrange(birth_year)%>%select(birth_year)%>%head(1) `, or 3500 BCE, and ends at `r panth_mod%>%arrange(desc(birth_year))%>%select(birth_year)%>%head(1)`, spanning about 5000 years. This means that a mere 13.9% of women in the entire timeframe are considered historical figures.

### Simple Linear Regression - For All Figures

```{r estimating_popularity_sex}
m_pop_sex <- lm(historical_popularity_index ~ sex , data = panth_mod)
tidy(m_pop_sex) %>%
  select(term, estimate)
```

Here we estimated the historical popularity index using the `sex` variable using a simple linear regression. The slope for the categorical variable `sexMale` is 1.55, suggesting that historical figures who are men have, on average, an increase in their overall popularity index of 1.55 as long as all other variables are held constant. 
 
The linear model, based on the output, is:
 
`(historical_popularity_index) = 20.8(intercept) + 1.55(sexMale)`
 
```{r r-squared}
glance(m_pop_sex)$r.squared
```

We found that the r-squared for the linear model `m_pop` is 2.54%, which suggests that 2.54% of the variability of the data can be explained by the linear model and that the model does not fit our data very well. We think there might be a confounding variable, so we will look to see if `birth_year` is one.

### Simple Linear Regression - For All Figures Born After 1920

```{r women-after-1920}
panth_mod%>%
  filter(birth_year > 1920)%>%
  count(sex)%>%
  mutate(prop = n/sum(n))
```

For historical figures born after 1920, there are about 4 times as many male historical figures than female figures. This is intriguing because in this 85 year timeframe from 1920 - 2005, we have 1053 historical women out of a total of 1427 women in the entire timeframe. 

```{r new_m_pop_sex}
m_pop_sex2 <- lm(historical_popularity_index ~ sex , data = panth_mod %>%
                   filter(birth_year > 1920))
tidy(m_pop_sex2) %>%
  select(term, estimate)
```

In the previous model, we predicted the `historical_popularity_index` by `sex` across the entire ~5000 year time period of the data. The result was that historical figures who were men had, on average and with all other variables held constant, a popularity index score that was 1.55 points higher than that of women who were historical figures. However, in this model, we thought it would be interesting to analyze the 85 year timeframe after the year 1920, when women were given the right to vote in the U.S. and when, later in the century, women across the world where also granted greater rights. As a result, women made up about 20% of the historical figures as opposed to making up 13.9% of the historical figure population in the previous analysis.
 
The resulting linear model that only looked at the historical figures after 1920 is as follows:
 
`(historical_popularity_index) = 19.6(intercept) + 0.569(sexMale)`
 
The slope of the `sexMale` variable decreased significantly from the previous analysis. This shows that time is a factor that affects the historical popularity index of women specifically.

### Section 4 - How the Variable `Article_Languages` Affects `Historical_Popularity_Index`

### Simple Linear Regression

```{r article_languages_linear_model}
artlang_m <- lm(historical_popularity_index ~ article_languages, data = panth_mod)
tidy(artlang_m) %>%
  select(term, estimate)
```

Here we estimated the historical popularity index using the `article_langugaes` variable using a simple linear regression. The slope for the variable `article_languages` is 0.089, suggesting that for every one increase in the amount of languages the article has been translated, that historical figure, on average, will have an increase in their overall popularity index of 0.089 as long as all other variables are held constant.
 
The linear model, based on the output, is:
 
`(historical_popularity_index) = 21.839(intercept) + 0.089(article_languages)`

```{r r-squared_article_languages}
glance(artlang_m)$r.squared
```

We found that the r-squared for the linear model `artlang_m` is 21.6%, which suggests that 21.6% of the variability of the data can be explained by the linear model and that the model doesn't necessarily fit our data very well.

```{r visualizing-index-by-popularity}
panth_mod %>%
  filter(article_languages > 50 & continent != "Oceania")%>%
  ggplot(mapping = aes(y = historical_popularity_index, x = article_languages,
                       color = factor(continent))) + geom_point(alpha = .5) + 
    geom_smooth(method = "lm", se = FALSE) +
    labs(x = "Number of Article Languages", y = "Popularity Index", 
    title =
      "Effect of # of languages the article is translated into on popularity index", 
    color = "Continent") 
```

```{r greater-than-200}
panth_mod %>%
  select(full_name, historical_popularity_index, article_languages, country) %>%
  filter(article_languages > 200)
```

Because there are so many historical figures from Europe, there is a lot of clustering near the 50-60 language marker. Additionally, Europe and Asia's slopes are very similar. This could be because Europe has 6,073 figures with pages translated into 50 or more languages and very high popularity index scores or that Asia has 1,021 popular historical figures, but those figures have pages that have been translated into much more than 50 languages. For example, there is a historical figure that is an outlier considering Asia's spread in the visual. By filtering the data for the figure with a page translated into more than 200 languages, we identified this individual as Jesus Christ, whose Wikipedia page has been translated into 214 different languages.

```{r who-is-the-outlier}
panth_mod %>%
  select(full_name, historical_popularity_index, article_languages, country) %>%
  filter(historical_popularity_index < 20, article_languages > 175)
```

Interestingly, one of the historical figures has a low popularity index score, an outlier, but his/her wikipedia page has been translated into almost 200 different languages. After filtering the data to locate the point that had a popularity index score less than 20 and an article that was translated into more than 175 languages, we derived that the outlier historical figure from North America is Corbin Bleu, the actor from High School Musical.
 
After looking at how the variables `domain`, `sex`, and `article_languages` each affect historical popularity index, we see that they do play a role. To summarize our results and check to see if other variables affect the historical popularity index all at once, we will use a multiple linear regression full model.
 
### Multiple Linear Regression

```{r full_model}
m_full <- lm(historical_popularity_index ~ sex +
               domain +
               article_languages +
               continent +
               birth_year +
               continent * article_languages,
             data = panth_mod)
tidy(m_full) %>%
  select(term, estimate)
```

Here we estimated the historical popularity index using the `sex`, `domain`, `birth_year`, `article_languages`, and `continent` variables. We also included the interaction between continent and article languages. We would interpret the slope the same way we did with the simple linear regression above that had the `sex` variable only.

The linear model, based on the output, is:

`(historical_popularity_index) = 19.9(intercept) + 1.43(sexMale) + 0.335(domainBusiness & Law) + 0.275	(domainExploration) + 1.097(domainHumanities) + 0.398(domainInstitutions) + 0.763(domainPublic Figure) + 0.778(domainScience & Technology) - 4.20(domainSports) + 0.0893(article_languages)	+ 1.235	(continentAsia) + 2.063(continentEurope) + 1.322(continentNorth America	) + 0.980(continentOceania) + 2.68(continentSouth America) - 0.0235(article_languages:continentAsia) - 0.0209(article_languages:continentEurope) - 0.0227(article_languages:continentNorth America) - 0.0303(article_languages:continentOceania) - 0.0384(article_languages:continentSouth America) - 0.001813092(birth_year)`

```{r full_r-squared}
glance(m_full)$r.squared

glance(m_full)$adj.r.squared
```

The r-squared value for the full model is 63.5%, which means that more than half of the variability of the data can be explained by the model. This is a significant increase from the first regression model we did comparing `sex` and `historical_popularity_index` scores, which resulted in an r-squared of 2.54%. The adjusted r-squared is 63.4%. 

### Backwards Selection with AIC

```{r backwards_selection}
selected_model <- step(m_full, direction = "backward")

tidy(selected_model) %>%
  select(term, estimate)

glance(selected_model)$AIC
glance(selected_model)$r.squared
glance(selected_model)$adj.r.squared
```

After creating the selected model, we found that the full and selected models were identical, which indicates that the full model had the best predictive power. 

### The perfect historical popularity index

Based on the full and selected models, to have the highest popularity index score, one should:
be a man, study in the domain of the humanities, and live somewhere in the continent of South America. Additionally, the predicted popularity index score would increase if the figure was born before the year 0 (or before common era). This is because though the slope for `birth_year` is negative, the birth year itself for these figures is also negative (ie -3500), so the overall slope would be positive. 










### Distance

```{r haversine}
haversine <- function(long1, lat1, long2, lat2, round = 3) {
  # convert to radians
  long1 = long1 * pi / 180
  lat1  = lat1  * pi / 180
  long2 = long2 * pi / 180
  lat2  = lat2  * pi / 180
  
  R = 6371 # Earth mean radius in km
  
  a = sin((lat2 - lat1)/2)^2 + cos(lat1) * cos(lat2) * sin((long2 - long1)/2)^2
  d = R * 2 * asin(sqrt(a))
  
  return( round(d,round) ) # distance in km
}
```

```{r creating-distance}
panth_mod2 <- panth_mod%>%
  filter(domain == "Arts", continent == "Europe")%>%
  mutate(long.arts = longitude, lat.arts = latitude, name.arts = full_name)%>%
  head(300)%>%
  select(long.arts, lat.arts, name.arts, continent)

panth_mod3 <- panth_mod%>%
  filter(domain == "Science & Technology", continent == "Europe")%>%
  mutate(long.sci = longitude, lat.sci = latitude, name.sci = full_name)%>%
  head(300)%>%
  select(long.sci, lat.sci, name.sci, continent)

art_sci <- full_join(panth_mod2, panth_mod3, by = "continent")

art_sci <- art_sci%>%
  mutate(distance = haversine(long.arts, lat.arts, long.sci, lat.sci, round=3))
```

```{r dist-arts-sci}
art_sci %>%
  select(distance,name.arts,name.sci) %>%
  arrange(distance)
```

```{r comparing-dist}
art_sci_mindist <- art_sci %>%
  group_by(name.arts) %>%
  mutate(closest = min(distance)) 
  
art_sci_mindist%>%
  filter(closest == distance)%>%
  select(name.arts, closest, name.sci)
```

```{r creating-distance2}
panth_mod4 <- panth_mod%>%
  filter(domain == "Humanities", continent == "Europe")%>%
  mutate(long.hum = longitude, lat.hum = latitude, name.hum = full_name)%>%
  head(300)%>%
  select(long.hum, lat.hum, name.hum, continent)

panth_mod5 <- panth_mod%>%
  filter(domain == "Arts", continent == "Europe")%>%
  mutate(long.arts = longitude, lat.arts = latitude, name.arts = full_name)%>%
  head(300)%>%
  select(long.arts, lat.arts, name.arts, continent)

hum_art <- full_join(panth_mod4, panth_mod5, by = "continent")

hum_art <- hum_art %>%
  mutate(distance = haversine(long.arts, lat.arts, long.hum, lat.hum, round=3))
```

```{r dist}
hum_art %>%
  select(distance, name.arts, name.hum) %>%
  arrange(distance)
```

```{r comparing-dist2}
hum_art_mindist <- hum_art %>%
  group_by(name.arts) %>%
  mutate(closest = min(distance)) 
  
hum_art_mindist %>%
  filter(closest == distance)%>%
  select(name.arts, closest, name.hum)
```







the historgram

```{r distribution-of-index}
panth_mod %>%
  ggplot(mapping = aes(x = historical_popularity_index)) +
  geom_histogram(bins = 20) + 
  facet_wrap(~domain) +
  labs(title = "Distribution of Historical Popularity Index Scores", y = "Count", 
       x = "Historical Popularity Index Score", subtitle = "by Domain")

panth_mod %>%
  group_by(domain)%>%
  summarise(mean = mean(historical_popularity_index), 
            median = median(historical_popularity_index), 
            sd = sd(historical_popularity_index))
```
To get a better understanding of our dataset, we created a faceted histogram that shows the distribution of the historical popularity index scores for the historical figures across all of the domains in the dataset and ran summary statistics on the dataframe as a whole. The visual lets us see the true distribution of historical figures across all of the domains, letting us know which areas are the most popular and have produced the most historical figures.
We think this visual is important because it gives us a glimpse of how historical popularity index varies across the domains. We will comtinue looking at other variables to see if they contribute into the historical popularity index score.











## Conclusion
